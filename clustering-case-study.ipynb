{
 "cells": [
  {
   "attachments": {
    "ibm-cloud.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ibm-cloud.png](attachment:ibm-cloud.png)\n",
    "\n",
    "# CASE STUDY - Unsupervised Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\IpsitMohanty\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\IpsitMohanty\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\IpsitMohanty\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\IpsitMohanty\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\IpsitMohanty\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\IpsitMohanty\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ipsitmohanty\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Seaborn Installed Successfully!\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"✅ Seaborn Installed Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Seaborn theme applied successfully!\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use Seaborn's built-in style settings\n",
    "sns.set_theme(style=\"darkgrid\")  # Alternatives: \"whitegrid\", \"dark\", \"white\", \"ticks\"\n",
    "\n",
    "# Enable inline plotting in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ Seaborn theme applied successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-v0_8', 'seaborn-v0_8-bright', 'seaborn-v0_8-colorblind', 'seaborn-v0_8-dark', 'seaborn-v0_8-dark-palette', 'seaborn-v0_8-darkgrid', 'seaborn-v0_8-deep', 'seaborn-v0_8-muted', 'seaborn-v0_8-notebook', 'seaborn-v0_8-paper', 'seaborn-v0_8-pastel', 'seaborn-v0_8-poster', 'seaborn-v0_8-talk', 'seaborn-v0_8-ticks', 'seaborn-v0_8-white', 'seaborn-v0_8-whitegrid', 'tableau-colorblind10']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(plt.style.available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")  # Alternative: \"whitegrid\", \"ticks\", \"dark\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset Loaded Successfully!\n",
      "   customer_id  is_subscriber        country  age     customer_name  \\\n",
      "0            1              1  united_states   21        Kasen Todd   \n",
      "1            2              0      singapore   30      Ensley Garza   \n",
      "2            3              0  united_states   21     Lillian Carey   \n",
      "3            4              1  united_states   20  Beau Christensen   \n",
      "4            5              1      singapore   21    Ernesto Gibson   \n",
      "\n",
      "    subscriber_type  num_streams  \n",
      "0    aavail_premium           23  \n",
      "1  aavail_unlimited           12  \n",
      "2    aavail_premium           22  \n",
      "3      aavail_basic           19  \n",
      "4    aavail_premium           23  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the exact file path\n",
    "file_path = r\"D:\\Career\\Enterprise workflow\\Clustering-Case-Study-Local\\data\\aavail-target.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Confirm successful loading\n",
    "print(\"✅ Dataset Loaded Successfully!\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   customer_id      1000 non-null   int64 \n",
      " 1   is_subscriber    1000 non-null   int64 \n",
      " 2   country          1000 non-null   object\n",
      " 3   age              1000 non-null   int64 \n",
      " 4   customer_name    1000 non-null   object\n",
      " 5   subscriber_type  1000 non-null   object\n",
      " 6   num_streams      1000 non-null   int64 \n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 54.8+ KB\n",
      "None\n",
      "\n",
      "🔍 Missing Values in Each Column:\n",
      "customer_id        0\n",
      "is_subscriber      0\n",
      "country            0\n",
      "age                0\n",
      "customer_name      0\n",
      "subscriber_type    0\n",
      "num_streams        0\n",
      "dtype: int64\n",
      "\n",
      "📂 Dataset Columns:\n",
      "['customer_id', 'is_subscriber', 'country', 'age', 'customer_name', 'subscriber_type', 'num_streams']\n"
     ]
    }
   ],
   "source": [
    "# Display dataset information\n",
    "print(\"\\n📊 Dataset Information:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n🔍 Missing Values in Each Column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display column names\n",
    "print(\"\\n📂 Dataset Columns:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Seaborn theme applied successfully!\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use Seaborn's built-in style settings\n",
    "sns.set_theme(style=\"darkgrid\")  # Alternatives: \"whitegrid\", \"dark\", \"white\", \"ticks\"\n",
    "\n",
    "# Enable inline plotting in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ Seaborn theme applied successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # ✅ Import Seaborn\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "import imblearn.pipeline as pl\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE, SVMSMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synopsis\n",
    "\n",
    "  > We are now going to predict customer retention.  There are many models and many transforms to consider.  Use your\n",
    "    knowledge of pipelines and functions to ensure that your code makes it easy to compare and iterate over.  \n",
    "    \n",
    "  > Marketing has asked you to make a report on customer retention.  They would like you to come up with information     that can be used to improve current marketing strategy efforts.  The current plan is for marketing at AAVAiL to\n",
    "    collect more features on subscribers the and they would like to use your report as a proof-of-concept in order to     get buyin for this effort.\n",
    "  \n",
    "## Outline\n",
    "\n",
    "1. Create a churn prediction baseline model\n",
    "2. Use clustering as part of your prediction pipeline\n",
    "3. Run and experiment to see if re-sampling techniques improve your model\n",
    "\n",
    "## Data\n",
    "\n",
    "Here we load the data as we have already done.\n",
    "\n",
    "`aavail-target.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset Loaded Successfully!\n",
      "         country  age   subscriber_type  num_streams\n",
      "0  united_states   21    aavail_premium           23\n",
      "1      singapore   30  aavail_unlimited           12\n",
      "2  united_states   21    aavail_premium           22\n",
      "3  united_states   20      aavail_basic           19\n",
      "4      singapore   21    aavail_premium           23\n"
     ]
    }
   ],
   "source": [
    "# Define the correct file path\n",
    "file_path = r\"D:\\Career\\Enterprise workflow\\Clustering-Case-Study-Local\\data\\aavail-target.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"✅ Dataset Loaded Successfully!\")\n",
    "\n",
    "# Pull out the target variable\n",
    "_y = df.pop('is_subscriber')\n",
    "\n",
    "# Convert target: 0 (not subscriber) → 1 (churn), 1 (subscriber) → 0 (active)\n",
    "y = np.zeros(_y.size)\n",
    "y[_y == 0] = 1  # Mark churned customers as 1\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=['customer_id', 'customer_name'], inplace=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 1\n",
    "\n",
    "Using the train_test_split() function, create a stratified train test split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Stratified Train-Test Split Completed!\n",
      "Training Set Size: (800, 4), Test Set Size: (200, 4)\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define stratified train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df,  # Features\n",
    "    y,   # Target (churned vs. non-churned)\n",
    "    test_size=0.2,  # 20% test data\n",
    "    stratify=y,  # Ensures class distribution is maintained\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Confirm the split\n",
    "print(\"✅ Stratified Train-Test Split Completed!\")\n",
    "print(f\"Training Set Size: {X_train.shape}, Test Set Size: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Training Set Class Distribution:\n",
      "[569 231]\n",
      "\n",
      "📊 Test Set Class Distribution:\n",
      "[142  58]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check distribution in training set\n",
    "print(\"📊 Training Set Class Distribution:\")\n",
    "print(np.bincount(y_train.astype(int)))  # Counts for [Active (0), Churned (1)]\n",
    "\n",
    "# Check distribution in test set\n",
    "print(\"\\n📊 Test Set Class Distribution:\")\n",
    "print(np.bincount(y_test.astype(int)))  # Counts for [Active (0), Churned (1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2\n",
    "\n",
    "Create a baseline model.  We are going to test whether clustering followed by a model improves the results.  Then, we will test whether re-sampling techniques provide improvements.  Use a pipeline or another method, but create a baseline model given the data. Here is the ColumnTransformer we have used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing pipeline\n",
    "numeric_features = ['age', 'num_streams']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['country', 'subscriber_type']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encod', OrdinalEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric and categorical preprocessing\n",
    "numeric_features = ['age', 'num_streams']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Fill missing values with mean\n",
    "    ('scaler', StandardScaler())  # Standardize features\n",
    "])\n",
    "\n",
    "categorical_features = ['country', 'subscriber_type']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Fill missing categorical values\n",
    "    ('encoder', OrdinalEncoder())  # Convert categories to numbers\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ f1_score: 0.574\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest classifier (or change it to another model like Logistic Regression)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create a pipeline that integrates preprocessing and model training\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluate model performance using F1-score\n",
    "print(\"✅ f1_score:\", round(f1_score(y_test, y_pred, average='binary'), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 3\n",
    "\n",
    "The next part is to create a version of the classifier that uses identified clusters.  Here is a class to get you started.  It is a transformer like those that we have been working with.  There is an example of how to use it just below.  In this example 4 clusters were specified and their one-hot encoded versions were appended to the feature matrix.  Now using pipelines and/or functions compare the performance using cluster profiling as part of your matrix to the baseline.  You may compare multiple models and multiple clustering algorithms here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 4)\n",
      "(800, 5)\n",
      "(800, 4)\n",
      "(800, 8)\n"
     ]
    }
   ],
   "source": [
    "class KmeansTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.km = KMeans(n_clusters=self.n_clusters, n_init=20)\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        labels = self.km.predict(X)\n",
    "        return np.hstack((X, labels.reshape(-1, 1)))\n",
    "\n",
    "    def fit(self, X, y=None, *_):\n",
    "        self.km.fit(X)\n",
    "        labels = self.km.predict(X)\n",
    "        self.silhouette_score = round(silhouette_score(X, labels, metric='mahalanobis'), 3)\n",
    "        return self\n",
    "\n",
    "class GmmTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gmm = BayesianGaussianMixture(n_components=self.n_clusters, covariance_type='full',\n",
    "                                           max_iter=500, n_init=10, warm_start=True)        \n",
    "    def transform(self, X,*_):\n",
    "        probs = self.gmm.predict_proba(X) + np.finfo(float).eps\n",
    "        return np.hstack((X, probs))\n",
    "        \n",
    "    def fit(self, X, y=None, *_):\n",
    "        self.gmm.fit(X)\n",
    "        labels = self.gmm.predict(X)\n",
    "        self.silhouette_score = round(silhouette_score(X, labels, metric='mahalanobis'), 3)\n",
    "        return self\n",
    "    \n",
    "\n",
    "    \n",
    "## example for kmeans\n",
    "preprocessor.fit(X_train)\n",
    "X_train_pre = preprocessor.transform(X_train)    \n",
    "kt = KmeansTransformer(4)\n",
    "kt.fit(X_train_pre)\n",
    "X_train_kmeans = kt.transform(X_train_pre)\n",
    "print(X_train_pre.shape)\n",
    "print(X_train_kmeans.shape)   \n",
    "    \n",
    "## example for GMM  \n",
    "preprocessor.fit(X_train)\n",
    "X_train_pre = preprocessor.transform(X_train)    \n",
    "gt = GmmTransformer(4)\n",
    "gt.fit(X_train_pre)\n",
    "X_train_gmm = gt.transform(X_train_pre)\n",
    "print(X_train_pre.shape)  \n",
    "print(X_train_gmm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ KMeans Transformer\n",
    "class KmeansTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.km = KMeans(n_clusters=self.n_clusters, n_init=20, random_state=42)\n",
    "        \n",
    "    def transform(self, X, *_):\n",
    "        labels = self.km.predict(X)\n",
    "        return np.hstack((X, labels.reshape(-1, 1)))\n",
    "\n",
    "    def fit(self, X, y=None, *_):\n",
    "        self.km.fit(X)\n",
    "        labels = self.km.predict(X)\n",
    "        self.silhouette_score = round(silhouette_score(X, labels, metric='euclidean'), 3)\n",
    "        return self\n",
    "\n",
    "# ✅ Gaussian Mixture Model (GMM) Transformer\n",
    "class GmmTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters=4):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gmm = BayesianGaussianMixture(n_components=self.n_clusters, covariance_type='full',\n",
    "                                           max_iter=500, n_init=10, warm_start=True, random_state=42)        \n",
    "    def transform(self, X, *_):\n",
    "        probs = self.gmm.predict_proba(X) + np.finfo(float).eps\n",
    "        return np.hstack((X, probs))\n",
    "        \n",
    "    def fit(self, X, y=None, *_):\n",
    "        self.gmm.fit(X)\n",
    "        labels = self.gmm.predict(X)\n",
    "        self.silhouette_score = round(silhouette_score(X, labels, metric='euclidean'), 3)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering_pipeline(umodel):\n",
    "    \"\"\"\n",
    "    Evaluates different Pipelines comprised of:\n",
    "      - Preprocessing Transformer\n",
    "      - Clustering Transformer (KMeans or GMM)\n",
    "      - Classifier (Random Forest)\n",
    "\n",
    "    INPUT : 'gmm' or 'kmeans' to select the clustering model\n",
    "    OUTPUT : List of F1 scores for different cluster sizes\n",
    "    \"\"\"\n",
    "    \n",
    "    fscores = []  # Stores F1-scores for different cluster sizes\n",
    "    \n",
    "    for n_clusters in np.arange(3, 8):  # Iterate over cluster sizes (3 to 7)\n",
    "\n",
    "        # ✅ Create an instance of the binary classifier (Random Forest)\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "        if umodel == 'gmm':\n",
    "            # ✅ Create an instance of the GMM transformer with n_clusters clusters\n",
    "            cluster = GmmTransformer(n_clusters=n_clusters)  \n",
    "        elif umodel == 'kmeans':\n",
    "            # ✅ Create an instance of the KMeans transformer with n_clusters clusters\n",
    "            cluster = KmeansTransformer(n_clusters=n_clusters)  \n",
    "        else:\n",
    "            raise Exception(\"Invalid clustering model. Use 'gmm' or 'kmeans'.\")\n",
    "\n",
    "        # ✅ Create a Pipeline combining Preprocessing, Clustering, and Classifier\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clustering', cluster),\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "        \n",
    "        # ✅ Fit the pipeline on the training set\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        # ✅ Predict on the test set\n",
    "        y_pred = pipe.predict(X_test)\n",
    "\n",
    "        # ✅ Compute the F1-score and store it\n",
    "        score = round(f1_score(y_test, y_pred, average='binary'), 3)\n",
    "        fscores.append(score)\n",
    "    \n",
    "    return fscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clustering Performance Comparison:\n",
      "            kmeans    gmm\n",
      "n_clusters               \n",
      "3            0.552  0.525\n",
      "4            0.544  0.522\n",
      "5            0.586  0.534\n",
      "6            0.566  0.513\n",
      "7            0.549  0.542\n"
     ]
    }
   ],
   "source": [
    "## Run the different iterations for KMeans and GMM\n",
    "cp_results = {}\n",
    "cp_results['kmeans'] = run_clustering_pipeline('kmeans')\n",
    "cp_results['gmm'] = run_clustering_pipeline('gmm')\n",
    "\n",
    "## ✅ Display results in a DataFrame\n",
    "df_cp = pd.DataFrame(cp_results)\n",
    "df_cp[\"n_clusters\"] = [str(i) for i in np.arange(3, 8)]\n",
    "df_cp.set_index(\"n_clusters\", inplace=True)\n",
    "\n",
    "# ✅ Show results\n",
    "print(\"✅ Clustering Performance Comparison:\")\n",
    "print(df_cp.head(n=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "\n",
    "Run an experiment to see if you can you improve on your workflow with the addition of re-sampling techniques? For instance, you can copy the structure of the function created in the previous question and add a re-sampling transformer to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering_pipeline(umodel):\n",
    "    \"\"\"\n",
    "    Evaluates different Pipelines comprised of:\n",
    "      - Preprocessing Transformer\n",
    "      - Clustering Transformer (KMeans or GMM)\n",
    "      - Re-Sampling Transformer (SMOTE)\n",
    "      - Classifier (Random Forest)\n",
    "\n",
    "    INPUT : 'gmm' or 'kmeans' to select the clustering model\n",
    "    OUTPUT : List of F1 scores for different cluster sizes\n",
    "    \"\"\"\n",
    "    \n",
    "    fscores = []  # Stores F1-scores for different cluster sizes\n",
    "    \n",
    "    for n_clusters in np.arange(3, 8):  # Iterate over cluster sizes (3 to 7)\n",
    "\n",
    "        # ✅ Create an instance of the binary classifier (Random Forest)\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "        if umodel == 'gmm':\n",
    "            # ✅ Create an instance of the GMM transformer with n_clusters clusters\n",
    "            cluster = GmmTransformer(n_clusters=n_clusters)  \n",
    "        elif umodel == 'kmeans':\n",
    "            # ✅ Create an instance of the KMeans transformer with n_clusters clusters\n",
    "            cluster = KmeansTransformer(n_clusters=n_clusters)  \n",
    "        else:\n",
    "            raise Exception(\"Invalid clustering model. Use 'gmm' or 'kmeans'.\")\n",
    "\n",
    "        # ✅ Create a Pipeline combining Preprocessing, Clustering, SMOTE, and Classifier\n",
    "        pipe = ImbPipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('clustering', cluster),\n",
    "            ('resampling', SMOTE(random_state=42)),  # ✅ Apply SMOTE to balance the dataset\n",
    "            ('classifier', clf)\n",
    "        ])\n",
    "        \n",
    "        # ✅ Fit the pipeline on the training set\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        # ✅ Predict on the test set\n",
    "        y_pred = pipe.predict(X_test)\n",
    "\n",
    "        # ✅ Compute the F1-score and store it\n",
    "        score = round(f1_score(y_test, y_pred, average='binary'), 3)\n",
    "        fscores.append(score)\n",
    "    \n",
    "    return fscores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clustering with Re-Sampling Performance Comparison:\n",
      "            kmeans_smote  gmm_smote\n",
      "n_clusters                         \n",
      "3                  0.581      0.547\n",
      "4                  0.560      0.528\n",
      "5                  0.562      0.535\n",
      "6                  0.560      0.544\n",
      "7                  0.576      0.551\n"
     ]
    }
   ],
   "source": [
    "## Run the different iterations for KMeans and GMM with SMOTE\n",
    "cp_results = {}\n",
    "cp_results['kmeans_smote'] = run_clustering_pipeline('kmeans')\n",
    "cp_results['gmm_smote'] = run_clustering_pipeline('gmm')\n",
    "\n",
    "## ✅ Display results in a DataFrame\n",
    "df_cp = pd.DataFrame(cp_results)\n",
    "df_cp[\"n_clusters\"] = [str(i) for i in np.arange(3, 8)]\n",
    "df_cp.set_index(\"n_clusters\", inplace=True)\n",
    "\n",
    "# ✅ Show results\n",
    "print(\"✅ Clustering with Re-Sampling Performance Comparison:\")\n",
    "print(df_cp.head(n=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
